{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a dataframe used to create all visualizations for that recommendation\n",
    "\n",
    "\n",
    "\n",
    "Function used to fill in the dataframe\n",
    "If the concept name and record name exist in a row of the dataDF return a one. If they do not exist, check to see if the concept is contained in the dialect using the dialectDF (use filepath to determine dialect). If yes, return zero. if not in dialect return negative one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.1</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Warning: You are not running the latest version of PixieDust. Current is 1.1.1, Latest is 1.1.2</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div>Please copy and run the following command in a new cell to upgrade: <span style=\"background-color:#ececec;font-family:monospace;padding:0 5px\">!pip install --user --upgrade pixiedust</span></div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Please restart kernel after upgrading.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.8.4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import walk\n",
    "import fnmatch\n",
    "from ipywidgets import *\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select evaluation of a metadata collection and prepare it for analysis\n",
    "1. Query the data directory for evaluated data and use the results to populate a list \n",
    "2. Function that reads the selected csv into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-c5ee5b1f90c3>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-c5ee5b1f90c3>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    return EvaluatedMetadataDF\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 0.\n",
    "\n",
    "\n",
    "# 1.\n",
    "DataFiles=[]\n",
    "for path, subdirectories, filenames in os.walk('../data/'):\n",
    "    for filename in filenames:\n",
    "        if fnmatch.fnmatch(filename, '*Evaluated.csv.gz'):\n",
    "            DataFiles.append(os.path.join(path,filename).split(\"../data/\", 1)[-1])\n",
    "# 2.    \n",
    "def DataChoices(DataFile):\n",
    "    global EvaluatedMetadataDF\n",
    "    global dataFile\n",
    "    dataFile=DataFile\n",
    "    EvaluatedMetadataDF= pd.read_csv(os.path.join('../data', dataFile)\n",
    "    return EvaluatedMetadataDF\n",
    "\n",
    "interactive(DataChoices,DataFile=DataFiles)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read in the EvaluatedMetadata of the collection you want to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33867230d1c442a6bf94419e2ebf0a56"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive(DataChoices,DataFile=DataFiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LTERthroughTime/LTER_2013_EML_Evaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2016_EML_Evaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2009_EML_SimplifiedEvaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2010_EML_SimplifiedEvaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2016_EML_SimplifiedEvaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2005_EML_SimplifiedEvaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2005_EML_Evaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2008_EML_SimplifiedEvaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2012_EML_Evaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2011_EML_SimplifiedEvaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2014_EML_Evaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2011_EML_Evaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2009_EML_Evaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2012_EML_SimplifiedEvaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2007_EML_SimplifiedEvaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2014_EML_SimplifiedEvaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2006_EML_Evaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2015_EML_Evaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2010_EML_Evaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2015_EML_SimplifiedEvaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2006_EML_SimplifiedEvaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2007_EML_Evaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2013_EML_SimplifiedEvaluated.csv.gz',\n",
       " 'LTERthroughTime/LTER_2008_EML_Evaluated.csv.gz']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EvaluatedMetadataDF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ba8835303bb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mEvaluatedMetadataDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'EvaluatedMetadataDF' is not defined"
     ]
    }
   ],
   "source": [
    "EvaluatedMetadataDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a table with each record as a row of concept occurance counts. Each concept that occurs in the collection is a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Organization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-d266c4b6acbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFiledirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOrganization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mFilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mCollection\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mDialect\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_RAD.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mFilePath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFiledirectory\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mFilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mFilePath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgroup_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluatedMetadataDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Record'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Concept'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Organization' is not defined"
     ]
    }
   ],
   "source": [
    "FiledirectoryRAD=os.path.join('../data/',Organization)\n",
    "FilenameRAD='/'+Collection+'_'+Dialect+'_RAD.csv'\n",
    "FilePathRAD=FiledirectoryRAD+FilenameRAD\n",
    "FilePathRAD\n",
    "group_name = EvaluatedMetadataDF.groupby(['Record', 'Concept'], as_index=False)\n",
    "occuranceMatrix=group_name.size().unstack().reset_index()\n",
    "occuranceMatrix=occuranceMatrix.fillna(0)\n",
    "occuranceMatrix.to_csv(FilePath, mode = 'w', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum up the collection concept occurance \n",
    "Count up how many records contain the concept.\n",
    "Combine the two tables and add a collection, collection occurance, and average record occurance columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Organization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-7b309f1ba2f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFiledirectoryOccurance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOrganization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mFilenameOccurance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mCollection\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mDialect\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_Occurance.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mFilePathOccurance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFiledirectoryOccurance\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mFilenameOccurance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moccuranceSum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moccuranceMatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moccuranceCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moccuranceMatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moccuranceMatrix\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Organization' is not defined"
     ]
    }
   ],
   "source": [
    "FiledirectoryOccurance=os.path.join('../data/',Organization)\n",
    "FilenameOccurance='/'+Collection+'_'+Dialect+'_Occurance.csv'\n",
    "FilePathOccurance=FiledirectoryOccurance+FilenameOccurance\n",
    "occuranceSum=occuranceMatrix.sum()\n",
    "occuranceCount=occuranceMatrix[occuranceMatrix!=0].count()\n",
    "CollectionName=collectionDialect=dataFile.partition(\"/\")[2].partition(\"_Evaluated.csv\")[0]\n",
    "result = pd.concat([occuranceSum, occuranceCount], axis=1).reset_index()\n",
    "result.insert(1, 'Collection', CollectionName)\n",
    "result.insert(4, 'CollectionOccurance%', CollectionName)\n",
    "result.insert(4, 'AverageOccurancePerRecord', CollectionName)\n",
    "result.columns = ['Concept', 'Collection', 'ConceptCount', 'RecordCount', 'AverageOccurancePerRecord', 'CollectionOccurance%' ]\n",
    "NumberOfRecords = result.at[0, 'ConceptCount'].count('.xml')\n",
    "result['CollectionOccurance%'] = result['RecordCount']/NumberOfRecords\n",
    "result['CollectionOccurance%'] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in result['CollectionOccurance%']], index = result.index)\n",
    "\n",
    "result.at[0, 'ConceptCount'] = NumberOfRecords\n",
    "result.at[0, 'Concept'] = 'Number of Records'\n",
    "result['AverageOccurancePerRecord'] = result['RecordCount']/NumberOfRecords\n",
    "result.to_csv(FilePathOccurance, mode = 'w', index=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python with Pixiedust (Spark 2.2)",
   "language": "python",
   "name": "pythonwithpixiedustspark22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
